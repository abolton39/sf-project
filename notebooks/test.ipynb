{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import statsmodels.api as sm\n",
    "import joblib\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train=pd.read_csv('../data/exercise_26_train.csv')\n",
    "raw_test=pd.read_csv('../data/exercise_26_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536451\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "train_data = raw_train.copy(deep=True)\n",
    "# DATA PREP\n",
    "# Fixing the money and percents#\n",
    "train_data['x12'] = train_data['x12'].str.replace('$','')\n",
    "train_data['x12'] = train_data['x12'].str.replace(',','')\n",
    "train_data['x12'] = train_data['x12'].str.replace(')','')\n",
    "train_data['x12'] = train_data['x12'].str.replace('(','-')\n",
    "train_data['x12'] = train_data['x12'].astype(float)\n",
    "train_data['x63'] = train_data['x63'].str.replace('%','')\n",
    "train_data['x63'] = train_data['x63'].astype(float)\n",
    "\n",
    "# With mean imputation\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "train_all_imputed = pd.DataFrame(imputer.fit_transform(train_data.drop(columns=['y', 'x5', 'x31',  'x81' ,'x82'])), \n",
    "                                 columns=train_data.drop(columns=['y', 'x5', 'x31', 'x81', 'x82']).columns)\n",
    "std_scaler = StandardScaler()\n",
    "train_all_std = pd.DataFrame(std_scaler.fit_transform(train_all_imputed), columns=train_all_imputed.columns)\n",
    "\n",
    "# Ceate dummies\n",
    "dumb5 = pd.get_dummies(train_data['x5'], drop_first=True, prefix='x5', prefix_sep='_', dummy_na=True)\n",
    "train_all_std = pd.concat([train_all_std, dumb5], axis=1, sort=False)\n",
    "\n",
    "dumb31 = pd.get_dummies(train_data['x31'], drop_first=True, prefix='x31', prefix_sep='_', dummy_na=True)\n",
    "train_all_std = pd.concat([train_all_std, dumb31], axis=1, sort=False)\n",
    "\n",
    "dumb81 = pd.get_dummies(train_data['x81'], drop_first=True, prefix='x81', prefix_sep='_', dummy_na=True)\n",
    "train_all_std = pd.concat([train_all_std, dumb81], axis=1, sort=False)\n",
    "\n",
    "dumb82 = pd.get_dummies(train_data['x82'], drop_first=True, prefix='x82', prefix_sep='_', dummy_na=True)\n",
    "train_all_std = pd.concat([train_all_std, dumb82], axis=1, sort=False)\n",
    "train_all = pd.concat([train_all_std, train_data['y']], axis=1, sort=False)\n",
    "\n",
    "# INITIAL FEATURE SELECTION\n",
    "exploratory_LR = LogisticRegression(penalty='l1', fit_intercept=False, solver='liblinear')\n",
    "exploratory_LR.fit(train_all.drop(columns=['y']), train_all['y'])\n",
    "exploratory_results = pd.DataFrame(train_all.drop(columns=['y']).columns).rename(columns={0:'name'})\n",
    "exploratory_results['coefs'] = exploratory_LR.coef_[0]\n",
    "exploratory_results['coefs_squared'] = exploratory_results['coefs']**2\n",
    "var_reduced = exploratory_results.nlargest(25,'coefs_squared')\n",
    "variables = var_reduced['name'].to_list()\n",
    "\n",
    "# Convert boolean columns to numeric\n",
    "for col in variables:\n",
    "    if train_all[col].dtype == 'bool':\n",
    "        train_all[col] = train_all[col].astype(int)\n",
    "\n",
    "# Final model\n",
    "final_logit = sm.Logit(train_all['y'], train_all[variables])\n",
    "final_result = final_logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.366958\n",
      "1       0.824429\n",
      "2       0.134487\n",
      "3       0.471328\n",
      "4       0.323100\n",
      "          ...   \n",
      "9995    0.630504\n",
      "9996    0.438068\n",
      "9997    0.658542\n",
      "9998    0.161555\n",
      "9999    0.744278\n",
      "Length: 10000, dtype: float64\n",
      "0       0\n",
      "1       1\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9995    1\n",
      "9996    0\n",
      "9997    1\n",
      "9998    0\n",
      "9999    1\n",
      "Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_data = raw_test.copy(deep=True)\n",
    "# DATA PREP\n",
    "# Fixing the money and percents#\n",
    "test_data['x12'] = test_data['x12'].str.replace('$','')\n",
    "test_data['x12'] = test_data['x12'].str.replace(',','')\n",
    "test_data['x12'] = test_data['x12'].str.replace(')','')\n",
    "test_data['x12'] = test_data['x12'].str.replace('(','-')\n",
    "test_data['x12'] = test_data['x12'].astype(float)\n",
    "test_data['x63'] = test_data['x63'].str.replace('%','')\n",
    "test_data['x63'] = test_data['x63'].astype(float)\n",
    "\n",
    "# With mean imputation\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "train_all_imputed = pd.DataFrame(imputer.fit_transform(test_data.drop(columns=['x5', 'x31',  'x81' ,'x82'])), \n",
    "                                 columns=test_data.drop(columns=['x5', 'x31', 'x81', 'x82']).columns)\n",
    "std_scaler = StandardScaler()\n",
    "train_all_std = pd.DataFrame(std_scaler.fit_transform(train_all_imputed), columns=train_all_imputed.columns)\n",
    "\n",
    "# Ceate dummies\n",
    "dumb5 = pd.get_dummies(test_data['x5'], drop_first=True, prefix='x5', prefix_sep='_', dummy_na=True)\n",
    "train_all_std = pd.concat([train_all_std, dumb5], axis=1, sort=False)\n",
    "\n",
    "dumb31 = pd.get_dummies(test_data['x31'], drop_first=True, prefix='x31', prefix_sep='_', dummy_na=True)\n",
    "train_all_std = pd.concat([train_all_std, dumb31], axis=1, sort=False)\n",
    "\n",
    "dumb81 = pd.get_dummies(test_data['x81'], drop_first=True, prefix='x81', prefix_sep='_', dummy_na=True)\n",
    "train_all_std = pd.concat([train_all_std, dumb81], axis=1, sort=False)\n",
    "\n",
    "dumb82 = pd.get_dummies(test_data['x82'], drop_first=True, prefix='x82', prefix_sep='_', dummy_na=True)\n",
    "train_all = pd.concat([train_all_std, dumb82], axis=1, sort=False)\n",
    "\n",
    "train_all = train_all[variables]\n",
    "# Convert boolean columns to numeric\n",
    "for col in variables:\n",
    "    if train_all[col].dtype == 'bool':\n",
    "        train_all[col] = train_all[col].astype(int)\n",
    "\n",
    "probs = final_result.predict(train_all)\n",
    "predicted_class = (probs > 0.5).astype(int) # whatever threshold you want\n",
    "print(probs)\n",
    "print(predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
